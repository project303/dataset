<workflow-app xmlns="uri:oozie:workflow:1.0" name="simple-etl-user03">
 <start to="download-data-node"/>

   <action name="download-data-node">
     <shell xmlns="uri:oozie:shell-action:1.0">
       <job-tracker>yavam-001.labs247.com:8050</job-tracker>
       <name-node>hdfs://yavam-002.labs247.com:8020</name-node>
       <configuration>
         <property>
           <name>mapred.job.queue.name</name>
           <value>default</value>
         </property>
       </configuration>
       <exec>load_data-user03.sh</exec>
       <env-var>HADOOP_USER_NAME=${wf:user()}</env-var>
       <file>/user/user03/script/load_data-user03.sh</file>
     </shell>
     <ok to="external-table-node"/>
     <error to="kill_job"/>
   </action>

   <action name="external-table-node">
     <shell xmlns="uri:oozie:shell-action:1.0">
       <job-tracker>yavam-001.labs247.com:8050</job-tracker>
       <name-node>hdfs://yavam-002.labs247.com:8020</name-node>
       <configuration>
         <property>
           <name>mapred.job.queue.name</name>
           <value>default</value>
         </property>
       </configuration>
       <exec>external_table-user03.sh</exec>
       <env-var>HADOOP_USER_NAME=${wf:user()}</env-var>
       <file>/user/user03/script/external_table-user03.sh</file>
     </shell>
     <ok to="end"/>
     <error to="kill_job"/>
   </action>

   <kill name = "kill_job">
      <message>Job failed</message>
   </kill>

 <end name="end"/>
</workflow-app>
